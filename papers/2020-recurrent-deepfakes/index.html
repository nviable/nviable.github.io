<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><style data-href="/styles.386b0e0dba82b1a9bcb7.css">@import url(https://pro.fontawesome.com/releases/v5.13.0/css/all.css);.transition{transition:all .3s ease-in-out}.box-shadow,.page{box-shadow:0 0 6px 0 hsla(0,0%,100%,.1)}.page{max-width:1024px;margin:0 auto;padding:14px 28px;border:1px solid #060709;border-radius:4px}.page p{line-height:1.4}.page-research .paper-card{display:flex;flex-direction:row;text-decoration:none;align-items:center;padding:14px 0}.page-research .paper-card:hover{background-color:#060709;transform:scale(1.01)}.page-research .paper-card .year{font-family:Playfair Display;font-size:24px;font-weight:700;display:inline-block;padding:0 14px;align-self:baseline}.page-research .paper-card h3{margin:0;font-weight:400}.page-research .paper-card p{margin:0;color:#787878}.back-link{text-decoration:none;text-transform:uppercase;font-size:12px;display:inline-block}.back-link:before{content:"< "}.back-link:hover{transform:translate(-2px)}.page-home{display:flex;flex-wrap:wrap}.page-home .profile-image{border-radius:100%;width:100%;height:auto}.page-home .left,.page-home .right{width:100%}@media screen and (min-width:600px){.page-home .left{width:25%}.page-home .right{width:71%;padding:0 0 0 2%}}header{display:flex;flex-wrap:wrap;flex-direction:column;justify-content:center;align-items:center;margin:0}header .logo-container{font-weight:700;margin:0 14px 14px}header ul{display:flex;flex-direction:row;padding:0;margin:0;list-style:none}header ul li a{padding:14px;text-decoration:none;display:inline-block}header ul li a:hover{background-color:#060709}#footer .social li a,.transition{transition:all .3s ease-in-out}#footer{justify-content:center}#footer,#footer .social{display:flex;flex-direction:row}#footer .social{margin:0;padding:0;list-style:none}#footer .social li a{padding:14px;text-decoration:none;display:inline-block}#footer .social li a:hover{background-color:#060709}.card,.transition,a{transition:all .3s ease-in-out}.box-shadow{box-shadow:0 0 6px 0 hsla(0,0%,100%,.1)}.heading,h1,h2,h3,h4,h5{font-family:Playfair Display}body{font-family:Lato;background:#101418;font-size:18px}a,body{color:#ebebeb}.card{border-radius:5px}</style><meta name="generator" content="Gatsby 2.24.62"/><link as="script" rel="preload" href="/component---src-templates-paper-tsx-9b36cb7c9ed3eb3d652c.js"/><link as="script" rel="preload" href="/styles-89fd2ae28bdf06750a71.js"/><link as="script" rel="preload" href="/app-b55e90af6d9f29f67e61.js"/><link as="script" rel="preload" href="/framework-24894821fca4c6ccc1ce.js"/><link as="script" rel="preload" href="/webpack-runtime-4c50799cb641e6172bff.js"/><link as="fetch" rel="preload" href="/page-data/papers/2020-recurrent-deepfakes/page-data.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/app-data.json" crossorigin="anonymous"/></head><body><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><main><header><div class="logo-container">Nviable</div><div class="navigation-container"><ul class="nav"><li><a href="/">Home</a></li><li><a href="/research/">Research</a></li></ul></div></header><div class="page "><a class="back-link" href="/research/">Back to Papers</a><h1>Recurrent Convolutional Structures for Audio Spoof and Video Deepfake Detection</h1><span class="year">2020</span>|<span class="authors">Akash Chintha, Bao Thai, Saniat Javid Sohrawardi, Kartavya Manojbhai Bhatt, AndreaHickerson, Matthew Wright, Raymond Ptucha</span><div><p>Deepfakes, or artificially generated audiovisual renderings, can be used to defame a public figure or influence public opinion. With the recent discovery of generative adversarial networks, an attacker using a normal desktop computer fitted with an off-the-shelf graphics processing unit can make renditions realistic enough to easily fool a human observer. Detecting deepfakes is thus becoming important for reporters, social media platforms, and the general public. In this work, we introduce simple, yet surprisingly efficient digital forensic methods for audio spoof and visual deepfake detection. Our methods combine convolutional latent representations with bidirectional recurrent structures and entropy-based cost functions. The latent representations for both audio and video are carefully chosen to extract semantically rich information from the recordings. By feeding these into a recurrent framework, we can detect both spatial and temporal signatures of deepfake renditions. The entropy-based cost functions work well in isolation as well as in context with traditional cost functions. We demonstrate our methods on the FaceForensics++ and Celeb-DF video datasets and the ASVSpoof 2019 Logical Access audio datasets, achieving new benchmarks in all categories. We also perform extensive studies to demonstrate generalization to new domains and gain further insight into the effectiveness of the new architectures.
<a href="https://ieeexplore.ieee.org/abstract/document/9105097/">Link to paper</a></p></div><a class="back-link" href="/research/">Back to Papers</a></div><footer id="footer"><ul class="social"><li><a href="https://www.facebook.com/john.sohrawardi/" target="_blank"><i class="fab fa-facebook"></i></a></li><li><a href="https://instagram.com/nviable" target="_blank"><i class="fab fa-instagram"></i></a></li><li><a href="https://twitter.com/johnsohrawardi" target="_blank"><i class="fab fa-twitter"></i></a></li><li><a href="https://www.linkedin.com/in/sohrawardi/" target="_blank"><i class="fab fa-linkedin-in"></i></a></li><li><a href="https://steamcommunity.com/id/nviable/" target="_blank"><i class="fab fa-steam"></i></a></li><li><a href="https://www.twitch.tv/nviable" target="_blank"><i class="fab fa-twitch"></i></a></li></ul></footer></main></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/papers/2020-recurrent-deepfakes/";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"polyfill":["/polyfill-247f85a6ff5c53042944.js"],"app":["/app-b55e90af6d9f29f67e61.js"],"component---src-pages-404-tsx":["/component---src-pages-404-tsx-5e4abec624d0efb3005d.js"],"component---src-pages-index-tsx":["/component---src-pages-index-tsx-a1caa2ff0ece0d23fb9e.js"],"component---src-pages-research-tsx":["/component---src-pages-research-tsx-3a427c2b34ea771d97b2.js"],"component---src-templates-paper-tsx":["/component---src-templates-paper-tsx-9b36cb7c9ed3eb3d652c.js"]};/*]]>*/</script><script src="/polyfill-247f85a6ff5c53042944.js" nomodule=""></script><script src="/webpack-runtime-4c50799cb641e6172bff.js" async=""></script><script src="/framework-24894821fca4c6ccc1ce.js" async=""></script><script src="/app-b55e90af6d9f29f67e61.js" async=""></script><script src="/styles-89fd2ae28bdf06750a71.js" async=""></script><script src="/component---src-templates-paper-tsx-9b36cb7c9ed3eb3d652c.js" async=""></script></body></html>